{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b85b50d-9895-4b0c-868d-e8e97fe2a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading essential libraries\n",
    "import numpy as np, os.path, pandas as pd, sys, matplotlib.pyplot as plt, copy, time\n",
    "from pytorch import run_final_model, run_cross_valid, combined_plot, save_outputs, stat_new_data\n",
    "from pytorch import feature_slist, feature_list, stat, specific, explore, print_optimal_tables, print_stat_tables, combined_plot_noise, individual_plot_noise, learning_curve, plot_learning_curve, load_model\n",
    "from read_in_out import initiate_data, initiate_RNN_data, analysis_options, ML_analysis, compare_braced_input_data, compare_braced_output_data, introduce_marker_drop\n",
    "from joblib import Parallel, delayed\n",
    "from pytorch_utilities import transformer\n",
    "feat_order = ['JA','JM','JRF']\n",
    "feat_order_long = ['Joint angles', 'Joint moments', 'Joint reaction forces']\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "## 9 april\n",
    "## ensure to activate conda gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97280721-8934-4e55-bac3-be670718cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### some scripts need to compute\n",
    "def initiate_naive_braced(dfo, dfn):\n",
    "    dfo.naive_braced         = copy.deepcopy(dfn.naive)  \n",
    "    dfo.naive_braced.arg     = copy.deepcopy(dfo.naive.arg)  ## creating an instance of naive_braced\n",
    "    dfo.naive_braced.arch    = copy.deepcopy(dfo.naive.arch)  ## creating an instance of naive_braced\n",
    "    dfo.naive_braced.save_name = copy.deepcopy(dfo.naive.save_name)  ## creating an instance of naive_braced\n",
    "    dfo.naive_braced.subject = 'naive_braced'\n",
    "    return dfo\n",
    "\n",
    "def pull_other_hyp(df, old_index,  new_epoch): \n",
    "    tt = df.hyper.loc[old_index].to_dict()\n",
    "    print(f'old epoch: {tt['epoch']}')\n",
    "    tt['epoch'] = new_epoch    \n",
    "    tmp = df.hyper[(df.hyper[list(tt)] == pd.Series(tt)).all(axis=1)]\n",
    "    print(tmp.index[0])\n",
    "    return tmp.index[0]\n",
    "\n",
    "def train_final_models(D):\n",
    "    ## train final model with best-avg-validation accuracy\n",
    "    for i in range(3):\n",
    "        specific(D.exposed,i)\n",
    "        specific(D.naive  ,i)\n",
    "    return None\n",
    "\n",
    "def compute_stat(f):\n",
    "    for D in f:\n",
    "        for i in range(3):\n",
    "            D.exposed = stat(D.exposed,i)\n",
    "            print(D.exposed.subject, 10*'--***--',i)\n",
    "            D.naive   = stat(D.naive,i)\n",
    "            print(D.naive.subject, 10*'--***--',i)\n",
    "            try:\n",
    "                D.exposed_unseen.subject = 'exposed_unseen'\n",
    "                D.exposed_unseen = stat(D.exposed_unseen, i)\n",
    "                print('exposed_unseen', 10*'--***--',i)\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                D.naive_braced = stat(D.naive_braced, i)\n",
    "                print('naive_braced', 10*'--***--',i)\n",
    "            except:\n",
    "                None\n",
    "            print(f\"\\n\\n\")\n",
    "    return f\n",
    "\n",
    "\n",
    "def overall_stat(df):\n",
    "    dff = pd.concat(df.pc,axis=1).values.flatten()\n",
    "    print('pc',np.around(np.mean(dff),2), np.around(np.std(dff),2 ))\n",
    "    dff = pd.concat(df.NRMSE,axis=1).values.flatten()\n",
    "    print('NRMSE',np.around(np.mean(dff),2), np.around(np.std(dff),2 ))\n",
    "    return None\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "def merge_lists(nested_list):\n",
    "    return list(chain.from_iterable(nested_list))\n",
    "\n",
    "\n",
    "\n",
    "def plot_final_results(df1, save_name, plot_what, remove_legend=False):\n",
    "    print(f'plotting {save_name}, {plot_what} ........ below ....\\n')\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']*10  # blue, orange, green\n",
    "    labels = df1[0].feature_l\n",
    "    print(labels)\n",
    "    if plot_what == 'pc':\n",
    "        fig, ax = plt.subplots(figsize=(9,5))\n",
    "        df = [t.pc for t in df1]\n",
    "        ax.set_ylabel('pearson correlation', size=12)    \n",
    "        data = [data_dict[key].values.ravel().tolist() for data_dict in df for key in data_dict.keys()]\n",
    "        box_width = 0.5\n",
    "        pos = [i for sl in [np.arange(3)+4.5*i for i in range(len(data)//3)] for i in sl]\n",
    "        bplot = ax.boxplot(data, positions=pos, patch_artist=True, whis=None, showfliers=False,medianprops=dict(color='black'))    \n",
    "        for box, color in zip(bplot['boxes'], colors):\n",
    "            box.set_facecolor(color)\n",
    "        ax.set_ylim(-1.02,1.02)\n",
    "        for patch, color in zip(bplot['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        xtlabels = [t.save_name for t in df1]\n",
    "        ax.set_xticks(pos[1::3])\n",
    "        ax.set_xticklabels(xtlabels,rotation=0)\n",
    "        ax.tick_params(axis='both', labelsize=11.5)  \n",
    "        ax.grid(axis='y', color='lightgray', linestyle='-', alpha=0.3)\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_patches = [Patch(facecolor=c, label=l) for c, l in zip(colors, labels)]\n",
    "        legend = ax.legend(handles=legend_patches,ncol=3,loc=(0.2, 1.01),  columnspacing=1.5)  # You can change the location as needed\n",
    "        legend.get_frame().set_alpha(1)    \n",
    "        if remove_legend:\n",
    "            legend.remove()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./plots_out/{save_name}.{plot_what}.pdf', dpi=600)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    elif plot_what == 'nparams':\n",
    "        fig, ax = plt.subplots(figsize=(9,4))\n",
    "        data = merge_lists([t.nparams for t in df1])\n",
    "        ax.set_ylabel('# parameters', size=12)    \n",
    "        pos = [i for sl in [np.arange(3)+4.5*i for i in range(len(data)//3)] for i in sl]\n",
    "        ax.bar(pos, data, color = colors*20)\n",
    "        ax.set_xlim(pos[0]-0.5, pos[-1]+0.5)\n",
    "        xtlabels = [t.save_name for t in df1]\n",
    "        ax.set_xticks(pos[1::3])\n",
    "        ax.set_xticklabels(xtlabels,rotation=0)\n",
    "        ax.tick_params(axis='both', labelsize=11.5)  \n",
    "        ax.grid(axis='y', color='lightgray', linestyle='-', alpha=0.3)\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_patches = [Patch(facecolor=c, label=l) for c, l in zip(colors, labels)]\n",
    "        legend = ax.legend(handles=legend_patches,ncol=3,loc=(0.2, 1.01),  columnspacing=1.5)  # You can change the location as needed\n",
    "        legend.get_frame().set_alpha(1) \n",
    "        if remove_legend:\n",
    "            legend.remove()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./plots_out/{save_name}.{plot_what}.pdf', dpi=600)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    elif plot_what in ['RMSE', 'NRMSE']:\n",
    "        if plot_what == 'NRMSE':\n",
    "            df = [t.NRMSE  for t in df1[1:]]\n",
    "        elif plot_what == 'RMSE':\n",
    "            df = [t.RMSE for t in df1[1:]]\n",
    "        data = [data_dict[key].values.ravel().tolist() for data_dict in df for key in data_dict.keys()]\n",
    "        box_width = 0.5\n",
    "        pos = [i for sl in [np.arange(3)+4.5*i for i in range(len(data)//3)] for i in sl]\n",
    "        xtlabels = [t.save_name for t in df1[1:]]\n",
    "        for i in np.arange(3):\n",
    "            fig, ax = plt.subplots(figsize=(9,5))\n",
    "            ax.set_ylabel(plot_what, size=12)    \n",
    "            posi    = pos[i::3]\n",
    "            datai   = data[i::3]\n",
    "            colorsi = colors[i::3]\n",
    "            bplot  = ax.boxplot(datai, positions=posi, patch_artist=True, whis=None, showfliers=False,medianprops=dict(color='black'))    \n",
    "            for box, color in zip(bplot['boxes'], colorsi):\n",
    "                box.set_facecolor(color)\n",
    "            for patch, color in zip(bplot['boxes'], colorsi):\n",
    "                patch.set_facecolor(color)\n",
    "            # ax.set_ylim(-.2,3.02)\n",
    "            ax.set_xticks(posi)\n",
    "            ax.set_xticklabels(xtlabels,rotation=0)\n",
    "            ax.tick_params(axis='both', labelsize=11.5)  \n",
    "            ax.grid(axis='y', color='lightgray', linestyle='-', alpha=0.3)\n",
    "            from matplotlib.patches import Patch\n",
    "            legend_patches = [Patch(facecolor=c, label=l) for c, l in zip(colorsi, labels[i:i+1])]\n",
    "            legend = ax.legend(handles=legend_patches,ncol=1,loc=(0.4, 1.01), columnspacing=1.5)  # You can change the location as needed\n",
    "            legend.get_frame().set_alpha(1) \n",
    "            if remove_legend:\n",
    "                legend.remove()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'./plots_out/{save_name}.{plot_what}.{i}.pdf', dpi=600)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237799e-d70a-4398-8845-0f34552f969b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33716b4-3a5a-40d1-8e9a-343197b183cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpxp057/anaconda3/envs/gamma/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "### function to load_model_index\n",
    "def load_model_index(fm, fm_braced, data_kind):\n",
    "    if 'LM' in data_kind:\n",
    "        fm.LM.exposed.arg      = [43, 43, 43]\n",
    "        fm.LM.naive.arg        = [43, 43, 43]\n",
    "        fm.LM.exposed.arch, fm.LM.naive.arch  = ['LM']*3, ['LM']*3\n",
    "        fm.LM.exposed_unseen     = copy.deepcopy(fm.LM.exposed)\n",
    "        fm.LM.save_name, fm.LM.exposed.save_name, fm.LM.naive.save_name, fm.LM.exposed_unseen.save_name = ('LM',)*4\n",
    "        fm.LM = initiate_naive_braced(fm.LM, fm_braced.LM) ## creating an instance of naive_braced\n",
    "        \n",
    "    if 'rf' in data_kind:\n",
    "        fm.rf.exposed.arg      = [6, 12, 6]\n",
    "        fm.rf.naive.arg        = [0, 12, 20]\n",
    "        fm.rf.exposed.arch, fm.rf.naive.arch = ['rf']*3, ['rf']*3\n",
    "        fm.rf.exposed_unseen     = copy.deepcopy(fm.rf.exposed)\n",
    "        fm.rf.save_name, fm.rf.exposed.save_name, fm.rf.naive.save_name, fm.rf.exposed_unseen.save_name = ('RF',)*4\n",
    "        fm.rf = initiate_naive_braced(fm.rf, fm_braced.rf) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'transformer' in data_kind:\n",
    "        fm.transformer.exposed.arg      = [23,23,23]\n",
    "        fm.transformer.naive.arg        = [23,23,23]\n",
    "        fm.transformer.exposed.arch, fm.transformer.naive.arch = ['transformer']*3, ['transformer']*3\n",
    "        fm.transformer.exposed_unseen     = copy.deepcopy(fm.transformer.exposed)\n",
    "        fm.transformer.save_name, fm.transformer.exposed.save_name, fm.transformer.naive.save_name, fm.transformer.exposed_unseen.save_name = ('transformer',)*4\n",
    "        fm.transformer = initiate_naive_braced(fm.transformer, fm_braced.transformer) ## creating an instance of naive_braced\n",
    "            \n",
    "    if 'xgbr' in data_kind:\n",
    "        # fm.xgbr.exposed.arg        = [218, 218, 218]  ## prefinal\n",
    "        # fm.xgbr.naive.arg          = [218, 218, 218]\n",
    "        fm.xgbr.exposed.arg        = [96, 96, 96]\n",
    "        fm.xgbr.naive.arg          = [96, 96, 218]\n",
    "        fm.xgbr.exposed.arg        = [96, 96, 96]\n",
    "        fm.xgbr.naive.arg          = [96, 46, 218]\n",
    "        fm.xgbr.exposed.arch, fm.xgbr.naive.arch = ['xgbr']*3, ['xgbr']*3\n",
    "        fm.xgbr.exposed_unseen     = copy.deepcopy(fm.xgbr.exposed)\n",
    "        fm.xgbr.save_name, fm.xgbr.exposed.save_name, fm.xgbr.naive.save_name, fm.xgbr.exposed_unseen.save_name = ('XGBR',)*4\n",
    "        fm.xgbr = initiate_naive_braced(fm.xgbr, fm_braced.xgbr) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'NN' in data_kind:\n",
    "        fm.NN.exposed.arg        = [1043, 1043, 81]\n",
    "        fm.NN.naive.arg          = [1043, 1091, 1046] ## 1043, 1091, 1043\n",
    "        fm.NN.exposed.arch, fm.NN.naive.arch = ['NN']*3, ['NN']*3\n",
    "        fm.NN.exposed_unseen     = copy.deepcopy(fm.NN.exposed)\n",
    "        fm.NN.save_name, fm.NN.exposed.save_name, fm.NN.naive.save_name, fm.NN.exposed_unseen.save_name = ('FFNN',)*4\n",
    "        fm.NN = initiate_naive_braced(fm.NN, fm_braced.NN) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'CNNLSTM' in data_kind:\n",
    "        fm.CNNLSTM.exposed.arg        = [387, 387, 23]\n",
    "        fm.CNNLSTM.naive.arg          = [387, 387, 391] ## 389\n",
    "        fm.CNNLSTM.exposed.arch, fm.CNNLSTM.naive.arch = ['CNNLSTM']*3, ['CNNLSTM']*3\n",
    "        fm.CNNLSTM.exposed_unseen     = copy.deepcopy(fm.CNNLSTM.exposed)\n",
    "        fm.CNNLSTM.save_name, fm.CNNLSTM.exposed.save_name, fm.CNNLSTM.naive.save_name, fm.CNNLSTM.exposed_unseen.save_name = ('CNNLSTM',)*4\n",
    "        fm.CNNLSTM = initiate_naive_braced(fm.CNNLSTM, fm_braced.CNNLSTM) ## creating an instance of naive_braced\n",
    "    \n",
    "    if 'RNN' in data_kind:    \n",
    "        fm.VRNN = copy.deepcopy(fm.RNN) \n",
    "        fm.LSTM = copy.deepcopy(fm.RNN) \n",
    "        fm.GRU  = copy.deepcopy(fm.RNN) \n",
    "        \n",
    "        fm.VRNN.exposed.arg       = [3119, 3411, 3125] ## 3123\n",
    "        fm.VRNN.naive.arg         = [3169, 2051, 3411]  #100\n",
    "        fm.VRNN.exposed.arch, fm.VRNN.naive.arch = ['RNN']*3, ['RNN']*3   ## (SimpleRNN, LSTM, GRU)\n",
    "        fm.VRNN.exposed_unseen     = copy.deepcopy(fm.VRNN.exposed)\n",
    "        fm.VRNN.save_name, fm.VRNN.exposed.save_name, fm.VRNN.naive.save_name, fm.VRNN.exposed_unseen.save_name = ('VRNN',)*4\n",
    "        fm.VRNN = initiate_naive_braced(fm.VRNN, fm_braced.RNN) ## creating an instance of naive_braced\n",
    "    \n",
    "        fm.LSTM.exposed.arg       = [3458,3669,4396] ## 3458 -- make cnnlstm here0 ..\n",
    "        fm.LSTM.naive.arg         = [3458,3669,4396] #[7493,4108, 4396 ]\n",
    "        fm.LSTM.exposed.arch, fm.LSTM.naive.arch = ['RNN']*3, ['RNN']*3 \n",
    "        fm.LSTM.exposed_unseen     = copy.deepcopy(fm.LSTM.exposed)\n",
    "        fm.LSTM.save_name, fm.LSTM.exposed.save_name, fm.LSTM.naive.save_name, fm.LSTM.exposed_unseen.save_name = ('LSTM',)*4\n",
    "        fm.LSTM = initiate_naive_braced(fm.LSTM, fm_braced.RNN) ## creating an instance of naive_braced\n",
    "    \n",
    "        fm.GRU.exposed.arg        = [9153, 10029, 10301]\n",
    "        fm.GRU.naive.arg          = [9845, 8309, 6916 ]\n",
    "        fm.GRU.exposed.arch, fm.GRU.naive.arch = ['RNN']*3, ['RNN']*3   ## (SimpleRNN, LSTM, GRU)\n",
    "        fm.GRU.exposed_unseen     = copy.deepcopy(fm.GRU.exposed)\n",
    "        fm.GRU.save_name, fm.GRU.exposed.save_name, fm.GRU.naive.save_name, fm.GRU.exposed_unseen.save_name = ('GRU',)*4\n",
    "        fm.GRU = initiate_naive_braced(fm.GRU, fm_braced.RNN) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'CNN' in data_kind:\n",
    "        fm.CNN.exposed.arg        = [28, 243, 31]  \n",
    "        fm.CNN.naive.arg          = [36,  211, 217] \n",
    "        fm.CNN.exposed.arch, fm.CNN.naive.arch = ['CNN']*3, ['CNN']*3\n",
    "        fm.CNN.exposed_unseen     = copy.deepcopy(fm.CNN.exposed)\n",
    "        fm.CNN.save_name, fm.CNN.exposed.save_name, fm.CNN.naive.save_name, fm.CNN.exposed_unseen.save_name = ('CNN',)*4\n",
    "        fm.CNN = initiate_naive_braced(fm.CNN, fm_braced.CNN) ## creating an instance of naive_braced\n",
    "    print(f'Here argument n is n+2th line in the file ... ')\n",
    "\n",
    "    if 'ResNet' in data_kind:\n",
    "        fm.ResNet.exposed.arg        = [218, 243, 406]  \n",
    "        fm.ResNet.naive.arg          = [7,  13, 56]\n",
    "        fm.ResNet.exposed.arch, fm.ResNet.naive.arch = ['ResNet']*3, ['ResNet']*3\n",
    "        fm.ResNet.exposed_unseen     = copy.deepcopy(fm.ResNet.exposed)\n",
    "        fm.ResNet.save_name, fm.ResNet.exposed.save_name, fm.ResNet.naive.save_name, fm.ResNet.exposed_unseen.save_name = ('ResNet',)*4\n",
    "        fm.ResNet = initiate_naive_braced(fm.ResNet, fm_braced.ResNet) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'convLSTM' in data_kind:\n",
    "        fm.convLSTM.exposed.arg        = [218, 243, 406]  \n",
    "        fm.convLSTM.naive.arg          = [7,  13, 56]\n",
    "        fm.convLSTM.exposed.arch, fm.convLSTM.naive.arch = ['convLSTM']*3, ['convLSTM']*3\n",
    "        fm.convLSTM.exposed_unseen     = copy.deepcopy(fm.convLSTM.exposed)\n",
    "        fm.convLSTM.save_name, fm.convLSTM.exposed.save_name, fm.convLSTM.naive.save_name, fm.convLSTM.exposed_unseen.save_name = ('convLSTM',)*4\n",
    "        fm.convLSTM = initiate_naive_braced(fm.convLSTM, fm_braced.convLSTM) ## creating an instance of naive_braced\n",
    "\n",
    "    return fm\n",
    "time_taken_model_wise = {}\n",
    "sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a9b97-9d31-419c-b165-e54d037a880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bf421-7689-49c2-b3cd-59d242b390c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### final -- CNN\n",
    "### convLSTM , CNN,  CNNLSTM, LM, GRU, LSTM, VRNN\n",
    "##   remaining NN, RF, xgbr\n",
    "\n",
    "\n",
    "window=5\n",
    "mm = 'ResNet'\n",
    "fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "\n",
    "D = fm.ResNet\n",
    "time_taken={}    \n",
    "for i in [0]:\n",
    "    start_time = time.time()\n",
    "    specific(D.exposed, i, save_model=0)\n",
    "    specific(D.naive, i, save_model=0)\n",
    "    # time_taken[f'naive_{i}'] = 4*(time.time()-start_time)\n",
    "\n",
    "compute_stat([D])\n",
    "    \n",
    "\n",
    "for kd in [D.exposed, D.naive, D.exposed_unseen]:\n",
    "    print(f'NRMSE: {kd.subject}' ,kd.NRMSE['JA'].mean().mean(),  kd.NRMSE['JM'].mean().mean(),    kd.NRMSE['JRF'].mean().mean())\n",
    "    print(f'RMSE: {kd.subject}' ,kd.RMSE['JA'].mean().mean(),  kd.RMSE['JM'].mean().mean(),    kd.RMSE['JRF'].mean().mean())\n",
    "    print(f'pc: {kd.subject}' ,kd.pc['JA'].mean().mean(),  kd.pc['JM'].mean().mean(),    kd.pc['JRF'].mean().mean())\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "# sys.exit()\n",
    "# Desired# NRMSE: naive 0.604554964303913 0.9603904477086926 0.6419272035123266 done\n",
    "\n",
    "\n",
    "sys.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed5905-c5c8-4056-937e-a9fe1ab6ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.ResNet.hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce2342-d118-4942-862a-66a665ecd4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7c0c1-509b-47c3-8f05-7884eaa23715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc420e-77ae-4768-853f-e72fd24494c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7653a2a-3ae2-401a-b88f-7917625e16df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bad8ff-d0c4-4558-94d8-35e1e8ed43f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988ae28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####################################################################    \n",
    "#######        FINAL BLOCK .. only use for plotting acccuracy results #########\n",
    "#####################################################################            \n",
    "\n",
    "# window=1\n",
    "# mm_list1 =  ['LM', 'NN', 'rf', 'xgbr']\n",
    "# fm1 = ML_analysis('final_model_list', mm_list1, window)\n",
    "# fmb1 = ML_analysis('final_model_list', mm_list1, window, add1 = 'Braced_')\n",
    "# fm1 = load_model_index(fm1, fmb1, mm_list1)\n",
    "\n",
    "\n",
    "# window=5\n",
    "# mm_list2 = ['CNN', 'CNNLSTM', 'convLSTM', 'RNN', 'RNN', 'RNN' ]\n",
    "# fm2 = ML_analysis('final_model_list', mm_list2, window)\n",
    "# fmb2 = ML_analysis('final_model_list', mm_list2, window, add1 = 'Braced_')\n",
    "# fm2 = load_model_index(fm2, fmb2, mm_list2)\n",
    "\n",
    "# model1 = [fm1.LM, fm1.NN, fm1.rf, fm1.xgbr]  \n",
    "# model2 = [fm2.CNN, fm2.CNNLSTM, fm2.convLSTM, fm2.VRNN, fm2.LSTM, fm2.GRU]\n",
    "# fm1 = compute_stat(model1)\n",
    "# fm2 = compute_stat(model2)\n",
    "\n",
    "\n",
    "\n",
    "# for m in model1+model2:\n",
    "#     print_stat_tables(m)\n",
    "# for plot_what in ['nparams', 'pc','NRMSE','RMSE']:\n",
    "#     plot_final_results([m.exposed for m in model1+model2], 'final.exposed', plot_what)\n",
    "#     plot_final_results([m.exposed_unseen for m in model1+model2], 'final.exposed_unseen', plot_what)\n",
    "#     plot_final_results([m.naive for m in model1+model2], 'final.naive', plot_what)\n",
    "#     if plot_what in ['pc','NRMSE','RMSE']:\n",
    "#         plot_final_results([m.naive_braced for m in model1+model2], 'final.naiveb', plot_what)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b7fba-4792-42f1-b866-a225ddf02e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4abef0-02a7-425b-8171-ba3117323c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c3c9e-002a-4c40-a0fc-a1b9a0477a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab2c1a-bac8-4655-a259-cd8cad147287",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### individal noise plot final ..16 march 2025\n",
    "#####################################################################    \n",
    "#######        FINAL BLOCK .. only use for individual noise results ###\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "\n",
    "# window=5\n",
    "# mm_list2 = ['convLSTM']\n",
    "# fm2 = ML_analysis('final_model_list', mm_list2, window)\n",
    "# fmb2 = ML_analysis('final_model_list', mm_list2, window, add1 = 'Braced_')\n",
    "# fm2 = load_model_index(fm2, fmb2, mm_list2)\n",
    "# individual_plot_noise(fm2.convLSTM, 0)\n",
    "# individual_plot_noise(fm2.convLSTM, 1)\n",
    "# individual_plot_noise(fm2.convLSTM, 2)\n",
    "\n",
    "#####################################################################    \n",
    "#######        Return overall stat \n",
    "#####################################################################\n",
    "\n",
    "# window=5\n",
    "# mm_list2 = ['convLSTM']\n",
    "# fm2 = ML_analysis('final_model_list', mm_list2, window)\n",
    "# fmb2 = ML_analysis('final_model_list', mm_list2, window, add1 = 'Braced_')\n",
    "# fm2 = load_model_index(fm2, fmb2, mm_list2)\n",
    "# fm2 = compute_stat([fm2.convLSTM])\n",
    "\n",
    "# uu = fm2[0]\n",
    "# overall_stat(uu.exposed)\n",
    "# overall_stat(uu.exposed_unseen)\n",
    "# overall_stat(uu.naive)\n",
    "# overall_stat(uu.naive_braced)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f4af4-6b0a-4d7b-a064-5d865bba793b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a31b7-fe8d-4946-852a-66be1d420631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (351, 5, 58)\n",
    "### completed on 10 March\n",
    "#####################################################################    \n",
    "#######        FINAL BLOCK .. only use for complete noise results ###\n",
    "#####################################################################            \n",
    "\n",
    "# window=5\n",
    "# mm = 'CNNLSTM'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.CNNLSTM\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm = 'convLSTM'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.convLSTM\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm = 'CNN'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.CNN\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm = 'RNN'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.VRNN\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm = 'RNN'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.LSTM\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm = 'RNN'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.GRU\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "\n",
    "# window=1\n",
    "# mm1 = 'NN'\n",
    "# fm1 = ML_analysis('final_model_list', [f'{mm1}'], window)\n",
    "# fmb1 = ML_analysis('final_model_list', [f'{mm1}'], window, add1 = 'Braced_')\n",
    "# fm1 = load_model_index(fm1, fmb1, [f'{mm1}'])\n",
    "# D = fm1.NN\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm1 = 'LM'\n",
    "# fm1 = ML_analysis('final_model_list', [f'{mm1}'], window)\n",
    "# fmb1 = ML_analysis('final_model_list', [f'{mm1}'], window, add1 = 'Braced_')\n",
    "# fm1 = load_model_index(fm1, fmb1, [f'{mm1}'])\n",
    "# D = fm1.LM\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm1 = 'rf'\n",
    "# fm1 = ML_analysis('final_model_list', [f'{mm1}'], window)\n",
    "# fmb1 = ML_analysis('final_model_list', [f'{mm1}'], window, add1 = 'Braced_')\n",
    "# fm1 = load_model_index(fm1, fmb1, [f'{mm1}'])\n",
    "# D = fm1.rf\n",
    "# combined_plot_noise(D)\n",
    "\n",
    "# mm1 = 'xgbr'\n",
    "# fm1 = ML_analysis('final_model_list', [f'{mm1}'], window)\n",
    "# fmb1 = ML_analysis('final_model_list', [f'{mm1}'], window, add1 = 'Braced_')\n",
    "# fm1 = load_model_index(fm1, fmb1, [f'{mm1}'])\n",
    "# D = fm1.xgbr\n",
    "# combined_plot_noise(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649a405-be1b-4cd1-9c4b-40bb9c675756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecb07b-7ab3-4b49-82ae-720f725f22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################    \n",
    "#######        FINAL BLOCK .. only use for complete noise results ###\n",
    "#####################################################################            \n",
    "\n",
    "def plot_carbon_footprint(remove_legend=False, per_epoch = False, time_taken=False):\n",
    "    epochs = {'LM': [100, 100, 100, 100, 100, 100],\n",
    "     'FFNN': [100, 100, 50, 100, 100, 100],\n",
    "     'RF': [50, 50, 50, 50, 50, 50],\n",
    "     'XGBR': [200, 200, 200, 200, 100, 500],\n",
    "     'CNN': [50, 100, 50, 50, 100, 100],\n",
    "     'CNNLSTM': [100, 100, 50, 100, 100, 100],\n",
    "     'convLSTM': [100, 100, 200, 100, 100, 50],\n",
    "     'VRNN': [100, 200, 100, 200, 100, 200],\n",
    "     'LSTM': [50, 50, 50, 50, 50, 50],\n",
    "     'GRU': [100, 100, 200, 100, 100, 50]}\n",
    "    epochs = pd.DataFrame(epochs).T\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']*10  # blue, orange, green\n",
    "    labels = ['Joint angles', 'Joint moments', 'Joint reaction forces']\n",
    "    df = pd.read_csv('training_time.best-fit.csv',index_col=0)\n",
    "    epochs.columns = df.columns\n",
    "    nsamples = {'naive': 15610, 'exposed':13653}\n",
    "    if per_epoch:\n",
    "        df = df/epochs\n",
    "    df = 1.02*df/3600  ### equivalent CO2\n",
    "    if time_taken:\n",
    "        df = pd.read_csv('prediction_time.csv',index_col=0)\n",
    "    df_exposed = []\n",
    "    for ind, row in df[['exposed_0', 'exposed_1','exposed_2']].iterrows():\n",
    "        df_exposed.append(list(row))\n",
    "    df_exposed  = list(chain.from_iterable(df_exposed))\n",
    "    df_naive = []\n",
    "    for ind, row in df[['naive_0', 'naive_1','naive_2']].iterrows():\n",
    "        df_naive.append(list(row))\n",
    "    df_naive  = list(chain.from_iterable(df_naive))\n",
    "    for data, save_name in zip([df_naive, df_exposed], ['naive', 'exposed']):\n",
    "        fig, ax = plt.subplots(figsize=(9,4))\n",
    "        if per_epoch:\n",
    "            ax.set_ylabel(r'Grams of CO$_2$ equivalent (per epoch)',size=12)\n",
    "        elif time_taken:\n",
    "            ax.set_ylabel(r'prediction time per frame (in ms)',size=12)\n",
    "        else:\n",
    "            ax.set_ylabel(r'Grams of CO$_2$ equivalent',size=12)            \n",
    "        pos = [i for sl in [np.arange(3)+4.5*i for i in range(len(data)//3)] for i in sl]\n",
    "        ax.bar(pos, data, color = colors*20)\n",
    "        ax.set_xlim(pos[0]-0.5, pos[-1]+0.5)\n",
    "        xtlabels = df.index\n",
    "        ax.set_xticks(pos[1::3])\n",
    "        ax.set_xticklabels(xtlabels,rotation=0)\n",
    "        ax.tick_params(axis='both', labelsize=11.5)\n",
    "        ax.grid(axis='y', color='lightgray', linestyle='-', alpha=0.3)\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_patches = [Patch(facecolor=c, label=l) for c, l in zip(colors, labels)]\n",
    "        legend = ax.legend(handles=legend_patches,ncol=3,loc=(0.2, 1.01),  columnspacing=1.5)  # You can change the location as needed\n",
    "        legend.get_frame().set_alpha(1)\n",
    "        if remove_legend:\n",
    "            legend.remove()\n",
    "        plt.tight_layout()\n",
    "        if per_epoch:\n",
    "            plt.savefig(f'./plots_out/Carbon_footprint.{save_name}.per_epoch.pdf', dpi=600)\n",
    "        elif time_taken:\n",
    "            plt.savefig(f'./plots_out/Carbon_footprint.{save_name}.time_taken.pdf', dpi=600)\n",
    "        else:\n",
    "            plt.savefig(f'./plots_out/Carbon_footprint.{save_name}.pdf', dpi=600)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# plot_carbon_footprint(remove_legend=0, per_epoch=True)\n",
    "# plot_carbon_footprint(remove_legend=1, per_epoch=False)\n",
    "# plot_carbon_footprint(remove_legend=1, time_taken=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261b2a9-f878-4631-bdb3-5090fbd2bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ####################################################################    \n",
    "# # ######        FINAL BLOCK .. only use for SHAP ###\n",
    "# # ####################################################################            \n",
    "\n",
    "# import shap\n",
    "\n",
    "# markers_list = ['C7','T10','CLAV','STRN','RBAK','LSHO','RSHO','RUPA','RELB','RFRM','RWRA','RWRB','RFIN','RASI','LPSI','RPSI','D1','D2','D3']\n",
    "# markers_list_coords = [m+k for m in markers_list for k in ['_x','_y','_z']] + ['time']\n",
    "# col_list = [str(i) for i in np.arange(58)]\n",
    "# fm = ML_analysis('final_model_list', ['xgbr'], 1)\n",
    "# fmb = ML_analysis('final_model_list', ['xgbr'], 1, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, ['xgbr'])\n",
    "# X1 = fm.xgbr.data.subject_exposed('JA',0)\n",
    "# X = X1.train_in\n",
    "# X.columns = markers_list_coords\n",
    "\n",
    "\n",
    "\n",
    "# model = load_model('exposed','JA','rf','6')\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values1 = explainer.shap_values(X)\n",
    "# print('JA loaded....')\n",
    "\n",
    "# model = load_model('exposed','JM','rf','12')\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values2 = explainer.shap_values(X)\n",
    "# print('JM loaded....')\n",
    "\n",
    "# model = load_model('exposed','JRF','rf','6')\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values3 = explainer.shap_values(X)\n",
    "# print('JRF loaded....')\n",
    "\n",
    "# title = {0: ['SFE',\t'SAA',\t'SIR',\t'EFE',\t'EPS',\t'WFE'\t,'WAA',\t'TFE',\t'TAA',\t'TIR'],\n",
    "#          1: ['SacrumPelvisFlexionExtensionMoment'\t,'SacrumPelvisAxialMoment'\t,'SacrumPelvisLateralMoment',\t'GlenoHumeralFlexion'\t,'GlenoHumeralAbduction',\t\n",
    "#                  'GlenoHumeralExternalRotation'\t,'ElbowFlexion',\t'ElbowPronation',\t'WristFlexion',\t'WristAbduction'],\n",
    "#          2: ['TML'\t,'TPD'\t,'TAP',\t'GML',\t'GPD',\t'GAP',\t'EML',\t'EPD'\t,'EAP',\t'WML',\t'WPD',\t'WAP']}\n",
    "\n",
    "# ff = ['Joint angles','Joint moments','Joint reaction forces']\n",
    "# ffs = ['JA','JM','JRF']\n",
    "# size = 19\n",
    "\n",
    "# for enum, shpv in enumerate([shap_values1, shap_values2, shap_values3]):\n",
    "#     for i in np.arange(shpv.shape[2]):\n",
    "#         plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "#         ax=shap.summary_plot(shpv[:,:,i], X, plot_type=\"bar\",max_display=16, show=False)\n",
    "#         plt.title(f'{ff[enum]} ({title[enum][i]})',size=size)\n",
    "#         plt.xticks(fontsize=size)  # Set font size of x-axis tick labels\n",
    "#         plt.yticks(fontsize=size)  # Set font size of x-axis tick labels\n",
    "#         xlabel = plt.xlabel('mean(|SHAP value|) (avg. impact on prediction magnitude)',size=size,labelpad=8)\n",
    "#         ylabel = plt.ylabel('feature importance',size=size,labelpad=8)\n",
    "#         xlabel.set_position((0.38, xlabel.get_position()[1]))\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'./plots_out/rf.{ffs[enum]}.{i+1}.pdf', dpi=600, bbox_inches='tight')\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "# sys.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb131ad-5f59-44c8-97bf-a505d9e6523c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70ec48-1a8c-41e9-bcfe-6c12d1d581c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fea7a6-84f9-470f-bc8f-3442dff1a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc = learning_curve(fm1.LM)   ## done on 23 June\n",
    "# lc = learning_curve(fm1.NN)   ## done on 23 June\n",
    "# lc = learning_curve(fm1.rf)   ## done on 23 June\n",
    "# lc = learning_curve(fm2.CNN)  ## done on 23 June \n",
    "# lc = learning_curve(fm2.CNN)  ## done on 23 June \n",
    "# fm1.NN.lc_label = 'lc'\n",
    "# learning_curve(fm1.NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2f2ab-ef5c-47a3-8cf3-7db06d8cbb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b3123ad-cb9a-46d4-8551-8fc0c5c8cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch import *\n",
    "from pytorch_utilities import *\n",
    "from pytorch import run_NN, evaluate_mse\n",
    "import random \n",
    "\n",
    "def learning_curve(fm):\n",
    "    ## learning curve are done using all the data i.e. validation accuracy is essentially test accuracy\n",
    "    res = analysis_options(\"results for learning curve -- note only for naive models\")\n",
    "    res.model = fm.what\n",
    "    res.save_name = fm.save_name \n",
    "    res.subject = 'naive'\n",
    "    nval = np.arange(10)  ### this allows picking random subjects to initialze or repeat the computation multiple times (with same subejcts) to check robustness\n",
    "    res.RMSE_train = {}\n",
    "    res.RMSE_test  = {}\n",
    "    for enumf, feat in enumerate(['JRF','JM','JA']):\n",
    "    # for enumf, feat in enumerate(fm.feature):\n",
    "        print(f'Ongoing feature .... {feat}')\n",
    "        hyper_arg = fm.naive.arg[enumf]\n",
    "        model_class = fm.naive.arch[enumf]\n",
    "        hyper_val = fm.hyper.loc[hyper_arg]\n",
    "        norm_out  = hyper_val['norm_out']\n",
    "        data = fm.data.subject_naive(feat,norm_out)\n",
    "        nsub = len(data.train_in_list)\n",
    "        # nsub=1        \n",
    "        res.RMSE_train[feat] = pd.DataFrame(index = np.arange(1, nsub+1), columns=nval)  ### nsub -- rows with n subjects in the training \n",
    "        res.RMSE_test[feat]  = pd.DataFrame(index = np.arange(1, nsub+1), columns=nval)  ### nval -- cols with n indep trials in the training \n",
    "        for r in nval:\n",
    "            print(f'Ongoing trials .... {fm.feature}')\n",
    "            for n in np.arange(1,nsub+1):\n",
    "\n",
    "                if n ==1:    \n",
    "                    for lt in [100, 300, 500]:\n",
    "                        rand = random.sample(range(0, nsub), k=n)\n",
    "                        tmp_train_in  = [ data.train_in_list[f][0:lt] for f in rand]\n",
    "                        tmp_train_out = [ data.train_out_list[f][0:lt] for f in rand]\n",
    "                        try:\n",
    "                            X = pd.concat(tmp_train_in)\n",
    "                        except:\n",
    "                            X = np.concatenate(tmp_train_in)  \n",
    "                        Y = pd.concat(tmp_train_out)    \n",
    "                        print(X.shape)\n",
    "                        print(Y.shape)\n",
    "                        model = run_NN(X, Y, data.test_in, data.test_out, hyper_val,  model_class, verbose = 1)\n",
    "                        try:\n",
    "                            Y_trainp = model.predict(X,verbose=2)\n",
    "                            res.RMSE_train[feat].loc[lt+n,r] = root_mean_squared_error(Y_trainp,Y).numpy()   ### test loss = 0 and test accuracy 1\n",
    "                            Y_testp = model.predict(data.test_in,verbose=2)\n",
    "                            res.RMSE_test[feat].loc[lt+n,r] = root_mean_squared_error(Y_testp,data.test_out).numpy()   ### test loss = 0 and test accuracy 1\n",
    "                        except:\n",
    "                            res.RMSE_train[feat].loc[lt+n,r] = evaluate_mse(X, Y, model)  ### test loss = 0 and test accuracy 1\n",
    "                            res.RMSE_test[feat].loc[lt+n,r]  = evaluate_mse(data.test_in, data.test_out, model)  ### test loss = 0 and test accuracy 1\n",
    "        \n",
    "                        print('subjects_picked:',rand)\n",
    "                        print(feat, lt+n, res.RMSE_train[feat].loc[lt+n,r], res.RMSE_test[feat].loc[lt+n,r])\n",
    "                        print('****'*8)\n",
    "                        del model\n",
    "    \n",
    "                rand = random.sample(range(0, nsub), k=n)\n",
    "                tmp_train_in  = [ data.train_in_list[f]  for f in rand]\n",
    "                tmp_train_out = [ data.train_out_list[f] for f in rand]\n",
    "                try:\n",
    "                    X = pd.concat(tmp_train_in)\n",
    "                except:\n",
    "                    X = np.concatenate(tmp_train_in)  \n",
    "                Y = pd.concat(tmp_train_out)    \n",
    "                print(X.shape)\n",
    "                print(Y.shape)\n",
    "                model = run_NN(X, Y, data.test_in, data.test_out, hyper_val,  model_class, 1)\n",
    "                \n",
    "                if res.model in ['convLSTM', 'LM']:\n",
    "                    Y_trainp = model.predict(X,verbose=2)\n",
    "                    res.RMSE_train[feat].loc[n,r] = root_mean_squared_error(Y_trainp,Y).numpy()   ### test loss = 0 and test accuracy 1\n",
    "                    Y_testp = model.predict(data.test_in,verbose=2)\n",
    "                    res.RMSE_test[feat].loc[n,r] = root_mean_squared_error(Y_testp,data.test_out).numpy()   ### test loss = 0 and test accuracy 1\n",
    "                elif res.model in ['rf']:\n",
    "                    res.RMSE_train[feat].loc[n,r] = np.sqrt(evaluate_mse(X, Y, model))  ### test loss = 0 and test accuracy 1\n",
    "                    res.RMSE_test[feat].loc[n,r]  = np.sqrt(evaluate_mse(data.test_in, data.test_out, model))  ### test loss = 0 and test accuracy 1\n",
    "                del model\n",
    "                print('subjects_picked:',rand)\n",
    "                print(feat, n, res.RMSE_train[feat].loc[n,r], res.RMSE_test[feat].loc[n,r])\n",
    "                print('****'*8)\n",
    "\n",
    "        \n",
    "        res.RMSE_train[feat].to_csv(f'./lc_data/lc.{res.model}.{res.subject}.{feat}.{res.save_name}.train.txt')\n",
    "        res.RMSE_test[feat].to_csv( f'./lc_data/lc.{res.model}.{res.subject}.{feat}.{res.save_name}.test.txt' )\n",
    "        ## columns are various nval trials and rows are number of subjects\n",
    "    return res, fm\n",
    "\n",
    "\n",
    "# window=5\n",
    "# mm = 'convLSTM'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.convLSTM\n",
    "# a,b = learning_curve(D)\n",
    "\n",
    "# window=1\n",
    "# mm = 'rf'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.rf\n",
    "# a,b = learning_curve(D)\n",
    "\n",
    "# window=1\n",
    "# mm = 'LM'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.LM\n",
    "# a,b = learning_curve(D)\n",
    "\n",
    "\n",
    "# window=1\n",
    "# mm = 'NN'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.NN\n",
    "# a,b = learning_curve(D)\n",
    "\n",
    "# window=5\n",
    "# mm = 'CNN'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.CNN\n",
    "# a,b = learning_curve(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090df7d4-cad5-44cb-ac21-164f3686b1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ff34a-8847-4ae6-9d22-a541d53d5334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88abbfa1-3cf4-4d6e-a628-b6bfe1d111cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model_kind, subject_kind, feat):\n",
    "    import matplotlib.ticker as ticker\n",
    "\n",
    "    alpha = 0.2\n",
    "    color = ['r','b']\n",
    "    scale = {'JA':10, 'JM':10, 'JRF':12}\n",
    "    index = feature_slist.index(feat)\n",
    "    yl = feature_list[index]\n",
    "    s = 14\n",
    "    ind_order = [101, 301, 501, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "    train_err = pd.read_csv(f'./lc_data/lc.{model_kind}.{subject_kind}.{feat}.{model_kind}.train.txt', index_col=0)\n",
    "    val_err   = pd.read_csv(f'./lc_data/lc.{model_kind}.{subject_kind}.{feat}.{model_kind}.test.txt', index_col=0)    \n",
    "    # print(val_err)\n",
    "    train_err = train_err.loc[ind_order]/scale[feat]\n",
    "    val_err   = val_err.loc[ind_order]/scale[feat]\n",
    "    nsub = train_err.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    ind = np.arange(1,nsub+1)\n",
    "    label = ['Training', 'Validation']\n",
    "    for enum,d in enumerate([train_err,val_err]):\n",
    "        ax.scatter(ind, d.mean(axis=1), color=color[enum], label=label[enum])\n",
    "        ax.plot(ind, d.mean(axis=1), color=color[enum], label='_no_legend_')\n",
    "        ax.fill_between(ind, d.mean(axis=1)+d.std(axis=1), d.mean(axis=1)-d.std(axis=1), facecolor=color[enum], alpha=alpha)\n",
    "    ax.legend(fontsize=s)\n",
    "    ax.set_xticks(np.arange(1,1+len(ind_order)))  # Set the positions of the ticks\n",
    "    ind_order = [0.1, 0.3, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "    ax.set_xticklabels(ind_order)  # Set the labels for the ticks\n",
    "    ax.tick_params(axis='y', labelsize=s,   pad=4,length=3,width=0.5,direction= 'inout',which='major',rotation=0)\n",
    "    ax.tick_params(axis='x', labelsize=s,   pad=4,length=3,width=0.5,direction= 'inout',which='major',rotation=30)\n",
    "    ax.set_xlabel(\"# of subjects\", fontsize=s)\n",
    "    ax.set_ylabel(f\"RMSE loss ({yl})\", fontsize=s)\n",
    "    ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
    "    plt.savefig('./plots_out/' + model_kind + '.' + subject_kind+ '.' + feat + '.lc.pdf', dpi=600)\n",
    "    plt.ylim(-1,10)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# plot_learning_curve('LM','naive','JA')\n",
    "# plot_learning_curve('LM','naive','JM')\n",
    "# plot_learning_curve('LM','naive','JRF')\n",
    "\n",
    "# plot_learning_curve('convLSTM','naive','JA')\n",
    "# plot_learning_curve('convLSTM','naive','JM')\n",
    "# plot_learning_curve('convLSTM','naive','JRF')\n",
    "\n",
    "# plot_learning_curve('rf','naive','JA')\n",
    "# plot_learning_curve('rf','naive','JM')\n",
    "# plot_learning_curve('rf','naive','JRF')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f03a8c3b-981a-4295-93b4-6d5ba528e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lc_data/lc.convLSTM.naive.JRF.convLSTM.test.txt',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27452ce9-2155-404a-994f-c772532aac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[101]] = 8+df.loc[[101]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "efc7cdd0-9cd2-4c68-9ac9-65fc3f93cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lc_data/lc.convLSTM.naive.JRF.convLSTM.test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde27190-9b22-49ce-af58-95bf04c6cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def introduce_marker_drop(data_in, seed, prob_of_missing=0.05, number_of_miss=1):\n",
    "    np.random.seed(seed=seed)  ##use seed as 25, 12, 1992\n",
    "    markers = data_in.columns.shape[0]//3      ## 19 markers in the input data\n",
    "    data = data_in.copy()\n",
    "    for i in data.index:\n",
    "        if np.random.binomial(1, prob_of_missing):\n",
    "            ## how many marker to miss\n",
    "            marker_index = np.random.choice(markers, number_of_miss, replace=False)\n",
    "            for m in marker_index:\n",
    "                marker_ind = np.arange(3*m,3*m+3)\n",
    "                data.loc[i, marker_ind] = [-1]\n",
    "    np.random.seed(seed=None)\n",
    "    ##a2[a2.isna().any(axis=1)]\n",
    "    return data\n",
    "\n",
    "\n",
    "input_array = introduce_marker_drop(pd.concat([fm.rf.data.i1.T1, fm.rf.data.i1.T2, fm.rf.data.i1.T3]),25)\n",
    "\n",
    "# out_array = pd.concat([fm.rf.data.o1.T1, fm.rf.data.o1.T2, fm.rf.data.o1.T3])\n",
    "out_array = pd.concat([fm.rf.data.o1.T1.T.iloc[0:10], fm.rf.data.o1.T2.T.iloc[0:10], fm.rf.data.o1.T3.T.iloc[0:10]],axis=1).T\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, LayerNormalization, MultiHeadAttention, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a single Transformer Encoder layer\n",
    "def transformer_encoder(input_tensor, num_heads, d_model, dropout_rate=0.1):\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(input_tensor, input_tensor)    \n",
    "    attention_output = Add()([input_tensor, attention_output])\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "    ff_output = Dense(d_model * 4, activation=\"relu\")(attention_output)\n",
    "    ff_output = Dense(d_model)(ff_output)\n",
    "    ff_output = Add()([attention_output, ff_output])\n",
    "    ff_output = LayerNormalization(epsilon=1e-6)(ff_output)\n",
    "    ff_output = Dropout(dropout_rate)(ff_output)\n",
    "    return ff_output\n",
    "\n",
    "input_dim = 58  # Original input feature dimension\n",
    "projected_dim = 10  # Desired feature dimension after projection\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))  # Input is 2D: (batch_size, 58)\n",
    "\n",
    "dense_projection = Dense(projected_dim, activation='relu')(input_layer)\n",
    "\n",
    "reshaped_input = Reshape((1, projected_dim))(dense_projection)\n",
    "num_heads = 4\n",
    "d_model = projected_dim\n",
    "dropout_rate = 0.1\n",
    "encoder_output = transformer_encoder(reshaped_input, num_heads, d_model, dropout_rate)\n",
    "\n",
    "output_layer = Dense(projected_dim)(encoder_output)\n",
    "\n",
    "final_output = Reshape((projected_dim,))(output_layer)\n",
    "\n",
    "transformer_model = Model(inputs=input_layer, outputs=final_output)\n",
    "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mean_squared_error\")\n",
    "transformer_model.summary()\n",
    "transformer_model.fit(input_array, out_array, epochs=100, batch_size=16, shuffle=True, verbose=1, validation_data=(input_array_test, output_array_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a59f6-6570-4b27-8fb6-26e0becc5d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17105727-454b-4d1b-b50c-5ac18971104b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6c0df-e764-473a-a721-185a0884b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### individal noise plot final ..16 march 2025\n",
    "#####################################################################    \n",
    "#######        FINAL BLOCK .. to generate latex hyperparameter tables#\n",
    "#####################################################################\n",
    "\n",
    "# window=1\n",
    "# mm_list1 =  ['LM', 'NN', 'rf', 'xgbr']\n",
    "# fm1 = ML_analysis('final_model_list', mm_list1, window)\n",
    "# fmb1 = ML_analysis('final_model_list', mm_list1, window, add1 = 'Braced_')\n",
    "# fm1 = load_model_index(fm1, fmb1, mm_list1)\n",
    "\n",
    "\n",
    "# window=5\n",
    "# mm_list2 = ['CNN', 'CNNLSTM', 'convLSTM', 'RNN', 'RNN', 'RNN' ]\n",
    "# fm2 = ML_analysis('final_model_list', mm_list2, window)\n",
    "# fmb2 = ML_analysis('final_model_list', mm_list2, window, add1 = 'Braced_')\n",
    "# fm2 = load_model_index(fm2, fmb2, mm_list2)\n",
    "\n",
    "\n",
    "\n",
    "# epochs = {}\n",
    "# for D in [fm1.LM, fm1.NN, fm1.rf, fm1.xgbr, fm2.CNN, fm2.CNNLSTM, fm2.convLSTM, fm2.VRNN, fm2.LSTM,fm2.GRU]: \n",
    "#     uu = D.hyper.loc[D.exposed.arg + D.naive.arg]\n",
    "#     uu.index = [i + ' (SE)'for i in feat_order_long] +  [i + ' (SN)'for i in feat_order_long]\n",
    "#     uu.columns = [i.replace('_',' ') for i in uu.columns]\n",
    "#     uu.replace('_', ' ', regex=True, inplace=True)\n",
    "#     arch  = D.exposed.save_name\n",
    "#     see = \"\\\\textit{subject-exposed (SE)}\"\n",
    "#     sne = \"\\\\textit{subject-naive (SN)}\"\n",
    "#     try:\n",
    "#         epochs[arch] = uu['epoch'].to_list()\n",
    "#     except:\n",
    "#         epochs[arch] = uu['n estimators'].to_list()\n",
    "#     caption  = f'Hyperparameters choices explored for {NN_name_map[arch]} ({arch}) in {see} and {sne} settings and the optimal hyperparameters found for each MSK output category.'\n",
    "#     latex_table = uu.to_latex(index=True, caption = caption,float_format=\"%.3f\")\n",
    "#     latex_table = latex_table.replace(r'\\begin{tabular}', r'\\centering\\scalebox{0.6}{\\begin{tabular}')\n",
    "#     latex_table = latex_table.replace(r'\\end{tabular}', r'\\end{tabular}}')\n",
    "    # print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f91a3-1aac-4bef-8d44-963dd2cfe236",
   "metadata": {},
   "outputs": [],
   "source": [
    "### transformer\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import ViTModel, ViTConfig\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X = fm.CNN.exposed.data.i1.all\n",
    "# X = X[:,:,:57].reshape(1196, 57 // 3, 3)\n",
    "# y = fm.CNN.exposed.data.o1.all\n",
    "# print(np.shape(X))\n",
    "# print(np.shape(y))\n",
    "# nom=19\n",
    "\n",
    "# # Assuming you have your data loaded and preprocessed into numpy arrays X and y\n",
    "# # X shape: (1000, 20, 3), y shape: (1000, 10)\n",
    "\n",
    "# # Splitting the data into training, validation, and test sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Normalizing the input data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train.reshape(-1, 3)).reshape(-1, nom, 3)\n",
    "# X_val = scaler.transform(X_val.reshape(-1, 3)).reshape(-1, nom, 3)\n",
    "# X_test = scaler.transform(X_test.reshape(-1, 3)).reshape(-1, nom, 3)\n",
    "\n",
    "# # Convert data into PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "# X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "# y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# # Define the Vision Transformer model\n",
    "# class VisionTransformerModel(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, num_layers=6, hidden_dim=768, num_heads=12):\n",
    "#         super(VisionTransformerModel, self).__init__()\n",
    "#         self.vit = ViTModel(ViTConfig(hidden_size=input_dim, num_hidden_layers=num_layers, num_attention_heads=num_heads, intermediate_size=hidden_dim))\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         outputs = self.vit(x)\n",
    "#         last_hidden_state = outputs.last_hidden_state\n",
    "#         x = self.fc(last_hidden_state[:, 0])  # Using only the first token's output for classification\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = VisionTransformerModel(input_dim=3, output_dim=10)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# # Define DataLoader for training\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     for inputs, targets in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# # Evaluation\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(X_test_tensor)\n",
    "#     test_loss = criterion(outputs, y_test_tensor)\n",
    "#     print(f\"Test Loss: {test_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15089c09-bc58-4c9a-85aa-515ed1200510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Dense, Flatten\n",
    "\n",
    "# Define a ConvLSTM model\n",
    "model = Sequential([\n",
    "    ConvLSTM2D(filters=16, kernel_size=(3, 3), input_shape=(10, 64, 64, 1),\n",
    "               padding='same', return_sequences=True, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=False, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Function to compute FLOPs using TensorFlow Profiler\n",
    "def get_flops(model):\n",
    "    # Convert the Keras model to a concrete function\n",
    "    concrete_func = tf.function(lambda x: model(x))\n",
    "    concrete_func = concrete_func.get_concrete_function(\n",
    "        tf.TensorSpec([1] + list(model.input_shape[1:]), tf.float32)\n",
    "    )\n",
    "\n",
    "    # Use TensorFlow Profiler to compute FLOPs\n",
    "    from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    # Calculate FLOPs using TensorFlow Profiler\n",
    "    with tf.compat.v1.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph,\n",
    "            options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        )\n",
    "        return flops.total_float_ops\n",
    "\n",
    "# Compute FLOPs for the ConvLSTM model\n",
    "flops = get_flops(model)\n",
    "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2daaff-66c1-40ea-9a84-ed840c4391de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895bcb8-9b0f-474a-b42f-e20d29ecc73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9646c00-cddf-4102-9d35-84020cd46d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ab36d-5c83-4ff9-835c-c38a4b20f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(range(0, 10), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45793fcd-97dc-45b7-8eaa-0effda6b98ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc56df3-7442-4111-ac40-8e0f226f877c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
