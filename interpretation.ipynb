{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b85b50d-9895-4b0c-868d-e8e97fe2a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading essential libraries\n",
    "import numpy as np, os.path, pandas as pd, sys, matplotlib.pyplot as plt, copy\n",
    "from pytorch import run_final_model, run_cross_valid, combined_plot, save_outputs, stat_new_data\n",
    "from pytorch import feature_slist, feature_list, stat, specific, explore, print_optimal_tables, print_stat_tables, combined_plot_noise, learning_curve, plot_learning_curve, load_model\n",
    "from read_in_out import initiate_data, initiate_RNN_data, analysis_options, ML_analysis, compare_braced_input_data, compare_braced_output_data\n",
    "from joblib import Parallel, delayed\n",
    "from pytorch_utilities import transformer\n",
    "feat_order = ['JA','JM','JRF']#,'MA','MF']\n",
    "import seaborn as sns\n",
    "\n",
    "## https://viso.ai/deep-learning/explainable-ai/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3f094-d3ea-4456-a277-630b4b6a098e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97280721-8934-4e55-bac3-be670718cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### some scripts need to compute\n",
    "def initiate_naive_braced(dfo, dfn):\n",
    "    dfo.naive_braced         = copy.deepcopy(dfn.naive)  \n",
    "    dfo.naive_braced.arg     = copy.deepcopy(dfo.naive.arg)  ## creating an instance of naive_braced\n",
    "    dfo.naive_braced.arch    = copy.deepcopy(dfo.naive.arch)  ## creating an instance of naive_braced\n",
    "    dfo.naive_braced.save_name = copy.deepcopy(dfo.naive.save_name)  ## creating an instance of naive_braced\n",
    "    dfo.naive_braced.subject = 'naive_braced'\n",
    "    return dfo\n",
    "\n",
    "def train_final_models(D):\n",
    "    ## train final model with best-avg-validation accuracy\n",
    "    for i in range(3):\n",
    "        specific(D.exposed,i)\n",
    "        specific(D.naive  ,i)\n",
    "    return None\n",
    "\n",
    "def compute_stat(f):\n",
    "    for D in f:\n",
    "        for i in range(3):\n",
    "            D.exposed = stat(D.exposed,i)\n",
    "            print(D.exposed.subject, 10*'--***--',i)\n",
    "            D.naive   = stat(D.naive,i)\n",
    "            print(D.naive.subject, 10*'--***--',i)\n",
    "            try:\n",
    "                D.exposed_unseen.subject = 'exposed_unseen'\n",
    "                D.exposed_unseen = stat(D.exposed_unseen, i)\n",
    "                print('exposed_unseen', 10*'--***--',i)\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                D.naive_braced = stat(D.naive_braced, i)\n",
    "                print('naive_braced', 10*'--***--',i)\n",
    "            except:\n",
    "                None\n",
    "            print(f\"\\n\\n\")\n",
    "    return f\n",
    "\n",
    "def avg_stat(fm):\n",
    "    for f in fm:\n",
    "        for j in [f.exposed, f.naive]:\n",
    "            a,b = [],[]\n",
    "            for i in f.feature:\n",
    "                a.append(j.NRMSE[i])\n",
    "                b.append(j.pc[i])\n",
    "            a = pd.concat(a, axis=1)\n",
    "            b = pd.concat(b, axis=1)\n",
    "            # print('%',np.around(np.mean(a),2),np.around(np.std(a),2), j.kind, j.subject, 'NRMSE')\n",
    "            # print('%',np.around(np.mean(b),2),np.around(np.std(b),2), j.kind, j.subject, 'pc')\n",
    "\n",
    "# avg_stat([fm.LM])\n",
    "from itertools import chain\n",
    "def merge_lists(nested_list):\n",
    "    return list(chain.from_iterable(nested_list))\n",
    "\n",
    "\n",
    "def plot_final_results(df1, save_name, plot_what):\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']*10  # blue, orange, green\n",
    "    labels = df1[0].feature_l\n",
    "\n",
    "    if plot_what == 'pc':\n",
    "        fig, ax = plt.subplots()\n",
    "        df = [t.pc for t in df1]\n",
    "        ax.set_ylabel('pearson correlation', size=12)    \n",
    "        data = [data_dict[key].values.ravel().tolist() for data_dict in df for key in data_dict.keys()]\n",
    "        box_width = 0.5\n",
    "        pos = [i for sl in [np.arange(3)+4.5*i for i in range(len(data)//3)] for i in sl]\n",
    "        bplot = ax.boxplot(data, positions=pos, patch_artist=True, whis=None, showfliers=False,medianprops=dict(color='black'))    \n",
    "        for box, color in zip(bplot['boxes'], colors):\n",
    "            box.set_facecolor(color)\n",
    "        ax.set_ylim(-1.02,1.02)\n",
    "        for patch, color in zip(bplot['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        xtlabels = [t.save_name for t in df1]\n",
    "        ax.set_xticks(pos[1::3])\n",
    "        ax.set_xticklabels(xtlabels,rotation=45)\n",
    "        ax.tick_params(axis='both', labelsize=12)  \n",
    "        ax.grid(axis='y', color='lightgray', linestyle='-', alpha=0.3)\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_patches = [Patch(facecolor=c, label=l) for c, l in zip(colors, labels)]\n",
    "        legend = ax.legend(handles=legend_patches,ncol=3,bbox_to_anchor=(1.01, 1.09), loc = 'upper right',  columnspacing=1.5)  # You can change the location as needed\n",
    "        legend.get_frame().set_alpha(1)     \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./plots_out/{save_name}.{plot_what}.pdf', dpi=600)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    elif plot_what == 'nparams':\n",
    "        fig, ax = plt.subplots()\n",
    "        data = merge_lists([t.nparams for t in df1])\n",
    "        ax.set_ylabel('# parameters', size=12)    \n",
    "        pos = [i for sl in [np.arange(3)+4.5*i for i in range(len(data)//3)] for i in sl]\n",
    "        ax.bar(pos, data, color = colors*20)\n",
    "        ax.set_xlim(pos[0]-0.5, pos[-1]+0.5)\n",
    "        xtlabels = [t.save_name for t in df1]\n",
    "        ax.set_xticks(pos[1::3])\n",
    "        ax.set_xticklabels(xtlabels,rotation=45)\n",
    "        ax.tick_params(axis='both', labelsize=12)  \n",
    "        ax.grid(axis='y', color='lightgray', linestyle='-', alpha=0.3)\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_patches = [Patch(facecolor=c, label=l) for c, l in zip(colors, labels)]\n",
    "        legend = ax.legend(handles=legend_patches,ncol=3,bbox_to_anchor=(1.01, 1.09), loc = 'upper right',  columnspacing=1.5)  # You can change the location as needed\n",
    "        legend.get_frame().set_alpha(1) \n",
    "        # plt.tight_layout()\n",
    "        plt.savefig(f'./plots_out/{save_name}.{plot_what}.pdf', dpi=600)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    elif plot_what in ['RMSE', 'NRMSE']:\n",
    "        if plot_what == 'NRMSE':\n",
    "            df = [t.NRMSE  for t in df1[1:]]\n",
    "        elif plot_what == 'RMSE':\n",
    "            df = [t.RMSE for t in df1[1:]]\n",
    "        data = [data_dict[key].values.ravel().tolist() for data_dict in df for key in data_dict.keys()]\n",
    "        box_width = 0.5\n",
    "        pos = [i for sl in [np.arange(3)+4.5*i for i in range(len(data)//3)] for i in sl]\n",
    "        xtlabels = [t.save_name for t in df1[1:]]\n",
    "        for i in np.arange(3):\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.set_ylabel(plot_what, size=12)    \n",
    "            posi    = pos[i::3]\n",
    "            datai   = data[i::3]\n",
    "            colorsi = colors[i::3]\n",
    "            bplot  = ax.boxplot(datai, positions=posi, patch_artist=True, whis=None, showfliers=False,medianprops=dict(color='black'))    \n",
    "            for box, color in zip(bplot['boxes'], colorsi):\n",
    "                box.set_facecolor(color)\n",
    "            for patch, color in zip(bplot['boxes'], colorsi):\n",
    "                patch.set_facecolor(color)\n",
    "            # ax.set_ylim(-.2,3.02)\n",
    "            ax.set_xticks(posi)\n",
    "            ax.set_xticklabels(xtlabels,rotation=45)\n",
    "            ax.tick_params(axis='both', labelsize=12)  \n",
    "            ax.grid(axis='y', color='lightgray', linestyle='-', alpha=0.3)\n",
    "            from matplotlib.patches import Patch\n",
    "            legend_patches = [Patch(facecolor=c, label=l) for c, l in zip(colorsi, labels[i:i+1])]\n",
    "            legend = ax.legend(handles=legend_patches,ncol=1,bbox_to_anchor=(0.5, 1.1), loc = 'upper center',  columnspacing=1.5)  # You can change the location as needed\n",
    "            legend.get_frame().set_alpha(1) \n",
    "            # plt.title()        \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'./plots_out/{save_name}.{plot_what}.{i}.pdf', dpi=600)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33716b4-3a5a-40d1-8e9a-343197b183cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to load_model_index\n",
    "def load_model_index(fm, fm_braced, data_kind):\n",
    "    if 'LM' in data_kind:\n",
    "        fm.LM.exposed.arg      = [43, 43, 43]\n",
    "        fm.LM.naive.arg        = [43, 43, 43]\n",
    "        fm.LM.exposed.arch, fm.LM.naive.arch  = ['LM']*3, ['LM']*3\n",
    "        fm.LM.exposed_unseen     = copy.deepcopy(fm.LM.exposed)\n",
    "        fm.LM.save_name, fm.LM.exposed.save_name, fm.LM.naive.save_name, fm.LM.exposed_unseen.save_name = ('LM',)*4\n",
    "        fm.LM = initiate_naive_braced(fm.LM, fm_braced.LM) ## creating an instance of naive_braced\n",
    "        \n",
    "    if 'rf' in data_kind:\n",
    "        fm.rf.exposed.arg      = [5, 5, 5]\n",
    "        fm.rf.naive.arg        = [1, 5, 17]\n",
    "        fm.rf.exposed.arch, fm.rf.naive.arch = ['rf']*3, ['rf']*3\n",
    "        fm.rf.exposed_unseen     = copy.deepcopy(fm.rf.exposed)\n",
    "        fm.rf.save_name, fm.rf.exposed.save_name, fm.rf.naive.save_name, fm.rf.exposed_unseen.save_name = ('RF',)*4\n",
    "        fm.rf = initiate_naive_braced(fm.rf, fm_braced.rf) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'transformer' in data_kind:\n",
    "        fm.transformer.exposed.arg      = [23,23,23]\n",
    "        fm.transformer.naive.arg        = [23,23,23]\n",
    "        fm.transformer.exposed.arch, fm.transformer.naive.arch = ['transformer']*3, ['transformer']*3\n",
    "        fm.transformer.exposed_unseen     = copy.deepcopy(fm.transformer.exposed)\n",
    "        fm.transformer.save_name, fm.transformer.exposed.save_name, fm.transformer.naive.save_name, fm.transformer.exposed_unseen.save_name = ('transformer',)*4\n",
    "        fm.transformer = initiate_naive_braced(fm.transformer, fm_braced.transformer) ## creating an instance of naive_braced\n",
    "            \n",
    "    if 'xgbr' in data_kind:\n",
    "        fm.xgbr.exposed.arg        = [96, 96, 96]\n",
    "        fm.xgbr.naive.arg          = [96, 96, 218]\n",
    "        fm.xgbr.exposed.arch, fm.xgbr.naive.arch = ['xgbr']*3, ['xgbr']*3\n",
    "        fm.xgbr.exposed_unseen     = copy.deepcopy(fm.xgbr.exposed)\n",
    "        fm.xgbr.save_name, fm.xgbr.exposed.save_name, fm.xgbr.naive.save_name, fm.xgbr.exposed_unseen.save_name = ('XGBR',)*4\n",
    "        fm.xgbr = initiate_naive_braced(fm.xgbr, fm_braced.xgbr) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'NN' in data_kind:\n",
    "        fm.NN.exposed.arg        = [1043, 1043, 1043]\n",
    "        fm.NN.naive.arg          = [1043, 1091, 1046] \n",
    "        fm.NN.exposed.arch, fm.NN.naive.arch = ['NN']*3, ['NN']*3\n",
    "        fm.NN.exposed_unseen     = copy.deepcopy(fm.NN.exposed)\n",
    "        fm.NN.save_name, fm.NN.exposed.save_name, fm.NN.naive.save_name, fm.NN.exposed_unseen.save_name = ('FFNN',)*4\n",
    "        fm.NN = initiate_naive_braced(fm.NN, fm_braced.NN) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'CNNLSTM' in data_kind:\n",
    "        fm.CNNLSTM.exposed.arg        = [387, 387, 23]\n",
    "        fm.CNNLSTM.naive.arg          = [387, 387, 391] \n",
    "        fm.CNNLSTM.exposed.arch, fm.CNNLSTM.naive.arch = ['CNNLSTM']*3, ['CNNLSTM']*3\n",
    "        fm.CNNLSTM.exposed_unseen     = copy.deepcopy(fm.CNNLSTM.exposed)\n",
    "        fm.CNNLSTM.save_name, fm.CNNLSTM.exposed.save_name, fm.CNNLSTM.naive.save_name, fm.CNNLSTM.exposed_unseen.save_name = ('CNNLSTM',)*4\n",
    "        fm.CNNLSTM = initiate_naive_braced(fm.CNNLSTM, fm_braced.CNNLSTM) ## creating an instance of naive_braced\n",
    "    \n",
    "    if 'RNN' in data_kind:    \n",
    "        fm.VRNN = copy.deepcopy(fm.RNN) \n",
    "        fm.LSTM = copy.deepcopy(fm.RNN) \n",
    "        fm.GRU  = copy.deepcopy(fm.RNN) \n",
    "        \n",
    "        fm.VRNN.exposed.arg       = [3119, 3411, 3125] \n",
    "        fm.VRNN.naive.arg         = [3169, 2051, 3411] \n",
    "        fm.VRNN.exposed.arch, fm.VRNN.naive.arch = ['RNN']*3, ['RNN']*3   ## (SimpleRNN, LSTM, GRU)\n",
    "        fm.VRNN.exposed_unseen     = copy.deepcopy(fm.VRNN.exposed)\n",
    "        fm.VRNN.save_name, fm.VRNN.exposed.save_name, fm.VRNN.naive.save_name, fm.VRNN.exposed_unseen.save_name = ('VRNN',)*4\n",
    "        fm.VRNN = initiate_naive_braced(fm.VRNN, fm_braced.RNN) ## creating an instance of naive_braced\n",
    "    \n",
    "        fm.LSTM.exposed.arg       = [3458,3666,4396] \n",
    "        fm.LSTM.naive.arg         = [3458,3736,4396] \n",
    "        fm.LSTM.exposed.arch, fm.LSTM.naive.arch = ['RNN']*3, ['RNN']*3 \n",
    "        fm.LSTM.exposed_unseen     = copy.deepcopy(fm.LSTM.exposed)\n",
    "        fm.LSTM.save_name, fm.LSTM.exposed.save_name, fm.LSTM.naive.save_name, fm.LSTM.exposed_unseen.save_name = ('LSTM',)*4\n",
    "        fm.LSTM = initiate_naive_braced(fm.LSTM, fm_braced.RNN) ## creating an instance of naive_braced\n",
    "    \n",
    "        fm.GRU.exposed.arg        = [9153, 10029, 10301]\n",
    "        fm.GRU.naive.arg          = [9845, 8309, 6916 ]\n",
    "        fm.GRU.exposed.arch, fm.GRU.naive.arch = ['RNN']*3, ['RNN']*3   ## (SimpleRNN, LSTM, GRU)\n",
    "        fm.GRU.exposed_unseen     = copy.deepcopy(fm.GRU.exposed)\n",
    "        fm.GRU.save_name, fm.GRU.exposed.save_name, fm.GRU.naive.save_name, fm.GRU.exposed_unseen.save_name = ('GRU',)*4\n",
    "        fm.GRU = initiate_naive_braced(fm.GRU, fm_braced.RNN) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'CNN' in data_kind:\n",
    "        fm.CNN.exposed.arg        = [28, 243, 31]  \n",
    "        fm.CNN.naive.arg          = [36,  211, 217] \n",
    "        fm.CNN.exposed.arch, fm.CNN.naive.arch = ['CNN']*3, ['CNN']*3\n",
    "        fm.CNN.exposed_unseen     = copy.deepcopy(fm.CNN.exposed)\n",
    "        fm.CNN.save_name, fm.CNN.exposed.save_name, fm.CNN.naive.save_name, fm.CNN.exposed_unseen.save_name = ('CNN',)*4\n",
    "        fm.CNN = initiate_naive_braced(fm.CNN, fm_braced.CNN) ## creating an instance of naive_braced\n",
    "    print(f'Here argument n is n+2th line in the file ... ')\n",
    "\n",
    "    if 'convLSTM' in data_kind:\n",
    "        fm.convLSTM.exposed.arg        = [26, 51, 31]  \n",
    "        fm.convLSTM.naive.arg          = [36,  33, 26] \n",
    "        fm.convLSTM.exposed.arch, fm.convLSTM.naive.arch = ['convLSTM']*3, ['convLSTM']*3\n",
    "        fm.convLSTM.exposed_unseen     = copy.deepcopy(fm.convLSTM.exposed)\n",
    "        fm.convLSTM.save_name, fm.convLSTM.exposed.save_name, fm.convLSTM.naive.save_name, fm.convLSTM.exposed_unseen.save_name = ('convLSTM',)*4\n",
    "        fm.convLSTM = initiate_naive_braced(fm.convLSTM, fm_braced.convLSTM) ## creating an instance of naive_braced\n",
    "\n",
    "    if 'convLSTM' in data_kind:\n",
    "        fm.convLSTM.exposed.arg        = [218, 243, 406]  \n",
    "        fm.convLSTM.naive.arg          = [228, 225, 19] \n",
    "        fm.convLSTM.exposed.arch, fm.convLSTM.naive.arch = ['convLSTM']*3, ['convLSTM']*3\n",
    "        fm.convLSTM.exposed_unseen     = copy.deepcopy(fm.convLSTM.exposed)\n",
    "        fm.convLSTM.save_name, fm.convLSTM.exposed.save_name, fm.convLSTM.naive.save_name, fm.convLSTM.exposed_unseen.save_name = ('convLSTM',)*4\n",
    "        fm.convLSTM = initiate_naive_braced(fm.convLSTM, fm_braced.convLSTM) ## creating an instance of naive_braced\n",
    "\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518bf421-7689-49c2-b3cd-59d242b390c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpxp057/anaconda3/envs/gamma/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# window=5\n",
    "# mm = 'ResNet'\n",
    "# fm = ML_analysis('final_model_list', [f'{mm}'], window)\n",
    "# fmb = ML_analysis('final_model_list', [f'{mm}'], window, add1 = 'Braced_')\n",
    "# fm = load_model_index(fm, fmb, [f'{mm}'])\n",
    "# D = fm.ResNet\n",
    "\n",
    "# for i in [0,1,2]:\n",
    "#     specific(D.exposed, i)\n",
    "#     specific(D.naive, i)\n",
    "\n",
    "# print('--***--'*15)\n",
    "# compute_stat([D])\n",
    "\n",
    "# print(D.exposed.pc['JA'].mean().mean(),        D.exposed.pc['JM'].mean().mean(),        D.exposed.pc['JRF'].mean().mean())\n",
    "# print(D.naive.pc['JA'].mean().mean(),          D.naive.pc['JM'].mean().mean(),          D.naive.pc['JRF'].mean().mean())\n",
    "# print(D.exposed_unseen.pc['JA'].mean().mean(), D.exposed_unseen.pc['JM'].mean().mean(), D.exposed_unseen.pc['JRF'].mean().mean())\n",
    "\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795d2a0-3576-47d7-a452-81411bb8840b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4030fabc-e1df-4ae5-86ea-2f4df4e29a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp model_out_back2/model_LM_JA_exposed.hv_43.keras model_out/model_LM_JA_exposed.hv_43.keras\n",
      "cp model_out_back2/model_LM_JM_exposed.hv_43.keras model_out/model_LM_JM_exposed.hv_43.keras\n",
      "cp model_out_back2/model_LM_JRF_exposed.hv_43.keras model_out/model_LM_JRF_exposed.hv_43.keras\n",
      "cp model_out_back2/model_LM_JA_naive.hv_43.keras model_out/model_LM_JA_naive.hv_43.keras\n",
      "cp model_out_back2/model_LM_JM_naive.hv_43.keras model_out/model_LM_JM_naive.hv_43.keras\n",
      "cp model_out_back2/model_LM_JRF_naive.hv_43.keras model_out/model_LM_JRF_naive.hv_43.keras\n",
      "cp model_out_back2/model_rf_JA_exposed.hv_6.pkl model_out/model_rf_JA_exposed.hv_6.pkl\n",
      "cp model_out_back2/model_rf_JM_exposed.hv_12.pkl model_out/model_rf_JM_exposed.hv_12.pkl\n",
      "cp model_out_back2/model_rf_JRF_exposed.hv_6.pkl model_out/model_rf_JRF_exposed.hv_6.pkl\n",
      "cp model_out_back2/model_rf_JA_naive.hv_0.pkl model_out/model_rf_JA_naive.hv_0.pkl\n",
      "cp model_out_back2/model_rf_JM_naive.hv_12.pkl model_out/model_rf_JM_naive.hv_12.pkl\n",
      "cp model_out_back2/model_rf_JRF_naive.hv_20.pkl model_out/model_rf_JRF_naive.hv_20.pkl\n",
      "cp model_out_back2/model_xgbr_JA_exposed.hv_96.json model_out/model_xgbr_JA_exposed.hv_96.json\n",
      "cp model_out_back2/model_xgbr_JM_exposed.hv_96.json model_out/model_xgbr_JM_exposed.hv_96.json\n",
      "cp model_out_back2/model_xgbr_JRF_exposed.hv_96.json model_out/model_xgbr_JRF_exposed.hv_96.json\n",
      "cp model_out_back2/model_xgbr_JA_naive.hv_96.json model_out/model_xgbr_JA_naive.hv_96.json\n",
      "cp model_out_back2/model_xgbr_JM_naive.hv_46.json model_out/model_xgbr_JM_naive.hv_46.json\n",
      "cp model_out_back2/model_xgbr_JRF_naive.hv_218.json model_out/model_xgbr_JRF_naive.hv_218.json\n",
      "cp model_out_back2/model_NN_JA_exposed.hv_1043.keras model_out/model_NN_JA_exposed.hv_1043.keras\n",
      "cp model_out_back2/model_NN_JM_exposed.hv_1043.keras model_out/model_NN_JM_exposed.hv_1043.keras\n",
      "cp model_out_back2/model_NN_JRF_exposed.hv_81.keras model_out/model_NN_JRF_exposed.hv_81.keras\n",
      "cp model_out_back2/model_NN_JA_naive.hv_1043.keras model_out/model_NN_JA_naive.hv_1043.keras\n",
      "cp model_out_back2/model_NN_JM_naive.hv_1091.keras model_out/model_NN_JM_naive.hv_1091.keras\n",
      "cp model_out_back2/model_NN_JRF_naive.hv_1046.keras model_out/model_NN_JRF_naive.hv_1046.keras\n",
      "cp model_out_back2/model_CNNLSTM_JA_exposed.hv_387.keras model_out/model_CNNLSTM_JA_exposed.hv_387.keras\n",
      "cp model_out_back2/model_CNNLSTM_JM_exposed.hv_387.keras model_out/model_CNNLSTM_JM_exposed.hv_387.keras\n",
      "cp model_out_back2/model_CNNLSTM_JRF_exposed.hv_23.keras model_out/model_CNNLSTM_JRF_exposed.hv_23.keras\n",
      "cp model_out_back2/model_CNNLSTM_JA_naive.hv_387.keras model_out/model_CNNLSTM_JA_naive.hv_387.keras\n",
      "cp model_out_back2/model_CNNLSTM_JM_naive.hv_387.keras model_out/model_CNNLSTM_JM_naive.hv_387.keras\n",
      "cp model_out_back2/model_CNNLSTM_JRF_naive.hv_391.keras model_out/model_CNNLSTM_JRF_naive.hv_391.keras\n",
      "cp model_out_back2/model_RNN_JA_exposed.hv_3119.keras model_out/model_RNN_JA_exposed.hv_3119.keras\n",
      "cp model_out_back2/model_RNN_JM_exposed.hv_3411.keras model_out/model_RNN_JM_exposed.hv_3411.keras\n",
      "cp model_out_back2/model_RNN_JRF_exposed.hv_3125.keras model_out/model_RNN_JRF_exposed.hv_3125.keras\n",
      "cp model_out_back2/model_RNN_JA_exposed.hv_3458.keras model_out/model_RNN_JA_exposed.hv_3458.keras\n",
      "cp model_out_back2/model_RNN_JM_exposed.hv_3669.keras model_out/model_RNN_JM_exposed.hv_3669.keras\n",
      "cp model_out_back2/model_RNN_JRF_exposed.hv_4396.keras model_out/model_RNN_JRF_exposed.hv_4396.keras\n",
      "cp model_out_back2/model_RNN_JA_exposed.hv_9153.keras model_out/model_RNN_JA_exposed.hv_9153.keras\n",
      "cp model_out_back2/model_RNN_JM_exposed.hv_10029.keras model_out/model_RNN_JM_exposed.hv_10029.keras\n",
      "cp model_out_back2/model_RNN_JRF_exposed.hv_10301.keras model_out/model_RNN_JRF_exposed.hv_10301.keras\n",
      "cp model_out_back2/model_RNN_JA_naive.hv_3169.keras model_out/model_RNN_JA_naive.hv_3169.keras\n",
      "cp model_out_back2/model_RNN_JM_naive.hv_2051.keras model_out/model_RNN_JM_naive.hv_2051.keras\n",
      "cp model_out_back2/model_RNN_JRF_naive.hv_3411.keras model_out/model_RNN_JRF_naive.hv_3411.keras\n",
      "cp model_out_back2/model_RNN_JA_naive.hv_3458.keras model_out/model_RNN_JA_naive.hv_3458.keras\n",
      "cp model_out_back2/model_RNN_JM_naive.hv_3669.keras model_out/model_RNN_JM_naive.hv_3669.keras\n",
      "cp model_out_back2/model_RNN_JRF_naive.hv_4396.keras model_out/model_RNN_JRF_naive.hv_4396.keras\n",
      "cp model_out_back2/model_RNN_JA_naive.hv_9845.keras model_out/model_RNN_JA_naive.hv_9845.keras\n",
      "cp model_out_back2/model_RNN_JM_naive.hv_8309.keras model_out/model_RNN_JM_naive.hv_8309.keras\n",
      "cp model_out_back2/model_RNN_JRF_naive.hv_6916.keras model_out/model_RNN_JRF_naive.hv_6916.keras\n",
      "cp model_out_back2/model_CNN_JA_exposed.hv_28.keras model_out/model_CNN_JA_exposed.hv_28.keras\n",
      "cp model_out_back2/model_CNN_JM_exposed.hv_243.keras model_out/model_CNN_JM_exposed.hv_243.keras\n",
      "cp model_out_back2/model_CNN_JRF_exposed.hv_31.keras model_out/model_CNN_JRF_exposed.hv_31.keras\n",
      "cp model_out_back2/model_CNN_JA_naive.hv_36.keras model_out/model_CNN_JA_naive.hv_36.keras\n",
      "cp model_out_back2/model_CNN_JM_naive.hv_211.keras model_out/model_CNN_JM_naive.hv_211.keras\n",
      "cp model_out_back2/model_CNN_JRF_naive.hv_217.keras model_out/model_CNN_JRF_naive.hv_217.keras\n",
      "cp model_out_back2/model_convLSTM_JA_exposed.hv_218.keras model_out/model_convLSTM_JA_exposed.hv_218.keras\n",
      "cp model_out_back2/model_convLSTM_JM_exposed.hv_243.keras model_out/model_convLSTM_JM_exposed.hv_243.keras\n",
      "cp model_out_back2/model_convLSTM_JRF_exposed.hv_406.keras model_out/model_convLSTM_JRF_exposed.hv_406.keras\n",
      "cp model_out_back2/model_convLSTM_JA_naive.hv_7.keras model_out/model_convLSTM_JA_naive.hv_7.keras\n",
      "cp model_out_back2/model_convLSTM_JM_naive.hv_13.keras model_out/model_convLSTM_JM_naive.hv_13.keras\n",
      "cp model_out_back2/model_convLSTM_JRF_naive.hv_56.keras model_out/model_convLSTM_JRF_naive.hv_56.keras\n"
     ]
    }
   ],
   "source": [
    "def return_ab(model_name):\n",
    "    data_kind = [model_name]\n",
    "    if 'LM' in data_kind:\n",
    "        a       = [43, 43, 43]\n",
    "        b       = [43, 43, 43]\n",
    "        \n",
    "    if 'rf' in data_kind:\n",
    "        a     = [6, 12, 6]\n",
    "        b        = [0, 12, 20]\n",
    "\n",
    "    if 'transformer' in data_kind:\n",
    "        a      = [23,23,23]\n",
    "        b        = [23,23,23]\n",
    "            \n",
    "    if 'xgbr' in data_kind:\n",
    "        a        = [96, 96, 96]\n",
    "        b         = [96, 46, 218]\n",
    "\n",
    "    if 'NN' in data_kind:\n",
    "        a       = [1043, 1043, 81]\n",
    "        b          = [1043, 1091, 1046] ## 1043, 1091, 1043\n",
    "\n",
    "    if 'CNNLSTM' in data_kind:\n",
    "        a        = [387, 387, 23]\n",
    "        b          = [387, 387, 391] ## 389\n",
    "\n",
    "\n",
    "    if 'RNN' in data_kind:    \n",
    "        a       = [3119, 3411, 3125] + [3458,3669,4396] + [9153, 10029, 10301]\n",
    "        b        = [3169, 2051, 3411] + [3458,3669,4396] + [9845, 8309, 6916 ]\n",
    "\n",
    "    if 'CNN' in data_kind:\n",
    "        a        = [28, 243, 31]  \n",
    "        b          = [36,  211, 217] \n",
    "\n",
    "    if 'convLSTM' in data_kind:\n",
    "        a       = [218, 243, 406]  \n",
    "        b         = [7,  13, 56]\n",
    "    f = ['JA','JM','JRF']*3\n",
    "    \n",
    "    if model_name in ['rf']:\n",
    "        a = [f'model_{model_name}_{f[enum]}_exposed.hv_{i}.pkl' for enum,i in  enumerate(a)]\n",
    "        b = [f'model_{model_name}_{f[enum]}_naive.hv_{i}.pkl' for enum,i in  enumerate(b)]\n",
    "    elif model_name in ['xgbr']:\n",
    "        a = [f'model_{model_name}_{f[enum]}_exposed.hv_{i}.json' for enum,i in  enumerate(a)]\n",
    "        b = [f'model_{model_name}_{f[enum]}_naive.hv_{i}.json' for enum,i in  enumerate(b)]\n",
    "    else:\n",
    "        a = [f'model_{model_name}_{f[enum]}_exposed.hv_{i}.keras' for enum,i in  enumerate(a)]\n",
    "        b = [f'model_{model_name}_{f[enum]}_naive.hv_{i}.keras' for enum,i in  enumerate(b)]\n",
    "        \n",
    "    return a+b \n",
    "\n",
    "model_lists = ['LM', 'rf', 'xgbr', 'NN','CNNLSTM',   'RNN' ,'CNN' , 'convLSTM'  ]\n",
    "path_lists = [return_ab(m) for m in  model_lists]\n",
    "\n",
    "import os\n",
    "\n",
    "for paths in path_lists:\n",
    "    for path in paths:\n",
    "        pathc = 'model_out_back2/'+path\n",
    "        pathn = 'model_out/'+path\n",
    "        if os.path.exists(pathc):\n",
    "            print('cp', pathc, pathn)\n",
    "        else:\n",
    "            print(f\"Path does not exist: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d48d91-db77-4bc4-a003-c54d08f7d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp model_out_back2/model_rf_JA_exposed.hv_6.pkl model_out/model_rf_JA_exposed.hv_6.pkl\n",
      "cp model_out_back2/model_rf_JM_exposed.hv_12.pkl model_out/model_rf_JM_exposed.hv_12.pkl\n",
      "cp model_out_back2/model_rf_JRF_exposed.hv_6.pkl model_out/model_rf_JRF_exposed.hv_6.pkl\n",
      "cp model_out_back2/model_rf_JA_naive.hv_0.pkl model_out/model_rf_JA_naive.hv_0.pkl\n",
      "cp model_out_back2/model_rf_JM_naive.hv_12.pkl model_out/model_rf_JM_naive.hv_12.pkl\n",
      "cp model_out_back2/model_rf_JRF_naive.hv_20.pkl model_out/model_rf_JRF_naive.hv_20.pkl\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3fbfd-4b46-471f-ba4d-b3afd6a6138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a569257-995d-4ce7-95b6-9e4d32c121e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681ea42-d2f6-4d2a-89ba-9628735d31e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb2edd-3d3f-440f-96df-438e4712e93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7653a2a-3ae2-401a-b88f-7917625e16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### transformer\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import ViTModel, ViTConfig\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X = fm.CNN.exposed.data.i1.all\n",
    "# X = X[:,:,:57].reshape(1196, 57 // 3, 3)\n",
    "# y = fm.CNN.exposed.data.o1.all\n",
    "# print(np.shape(X))\n",
    "# print(np.shape(y))\n",
    "# nom=19\n",
    "\n",
    "# # Assuming you have your data loaded and preprocessed into numpy arrays X and y\n",
    "# # X shape: (1000, 20, 3), y shape: (1000, 10)\n",
    "\n",
    "# # Splitting the data into training, validation, and test sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Normalizing the input data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train.reshape(-1, 3)).reshape(-1, nom, 3)\n",
    "# X_val = scaler.transform(X_val.reshape(-1, 3)).reshape(-1, nom, 3)\n",
    "# X_test = scaler.transform(X_test.reshape(-1, 3)).reshape(-1, nom, 3)\n",
    "\n",
    "# # Convert data into PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "# X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "# y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# # Define the Vision Transformer model\n",
    "# class VisionTransformerModel(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, num_layers=6, hidden_dim=768, num_heads=12):\n",
    "#         super(VisionTransformerModel, self).__init__()\n",
    "#         self.vit = ViTModel(ViTConfig(hidden_size=input_dim, num_hidden_layers=num_layers, num_attention_heads=num_heads, intermediate_size=hidden_dim))\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         outputs = self.vit(x)\n",
    "#         last_hidden_state = outputs.last_hidden_state\n",
    "#         x = self.fc(last_hidden_state[:, 0])  # Using only the first token's output for classification\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = VisionTransformerModel(input_dim=3, output_dim=10)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# # Define DataLoader for training\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     for inputs, targets in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# # Evaluation\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(X_test_tensor)\n",
    "#     test_loss = criterion(outputs, y_test_tensor)\n",
    "#     print(f\"Test Loss: {test_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7bad8ff-d0c4-4558-94d8-35e1e8ed43f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Braced data .. for normal data use empty string as input ...\n",
      "Here argument n is n+2th line in the file ... \n",
      "Loading Braced data .. for normal data use empty string as input ...\n",
      "Here argument n is n+2th line in the file ... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "w1, dk1 = 1, ['LM', 'NN', 'rf', 'xgbr']\n",
    "fm1 = ML_analysis('final_model_list', dk1, w1)\n",
    "fmb1 = ML_analysis('final_model_list', dk1, w1, add1 = 'Braced_')\n",
    "fm1 = load_model_index(fm1, fmb1, dk1)\n",
    "\n",
    "w2, dk2 = 5,  ['CNN', 'CNNLSTM', 'convLSTM', 'RNN','convLSTM'] ## [] ##\n",
    "fm2 = ML_analysis('final_model_list', dk2, w2)\n",
    "fmb2 = ML_analysis('final_model_list', dk2, w2, add1 = 'Braced_')\n",
    "fm2 = load_model_index(fm2, fmb2, dk2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988ae28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute_stat([fm2.CNN, fm2.CNNLSTM, fm2.convLSTM, fm2.LSTM, fm2.VRNN, fm2.GRU ])\n",
    "# compute_stat([fm1.rf, fm1.xgbr ])\n",
    "\n",
    "# for i in np.arange(1,337,1):\n",
    "#     fm1.xgbr.exposed.arg = [96, i, i]  ## JA: (96, 97, 98, 99, 144, 155, 167)\n",
    "#     fm1.xgbr.naive.arg   = [i, i, i]  ## 5, 1 , 1\n",
    "#     # for k in range(3):\n",
    "#     #     specific(fm1.xgbr.exposed, k)\n",
    "#     #     specific(fm1.xgbr.naive,   k)\n",
    "#     compute_stat([fm1.xgbr])\n",
    "    \n",
    "#     if max(\n",
    "#         fm1.xgbr.exposed.pc['JA'].mean().mean(),\n",
    "#         fm1.xgbr.exposed.pc['JRF'].mean().mean(),\n",
    "#         fm1.xgbr.naive.pc['JM'].mean().mean(),\n",
    "#         fm1.xgbr.naive.pc['JA'].mean().mean(),\n",
    "#         fm1.xgbr.naive.pc['JRF'].mean().mean()) > 0.75:\n",
    "#         print('exposed',\n",
    "#               fm1.xgbr.exposed.pc['JA'].mean().mean(), \n",
    "#               fm1.xgbr.exposed.pc['JM'].mean().mean(), \n",
    "#               fm1.xgbr.exposed.pc['JRF'].mean().mean(),\n",
    "#               'naive',\n",
    "#               fm1.xgbr.naive.pc['JA'].mean().mean(), \n",
    "#               fm1.xgbr.naive.pc['JM'].mean().mean(), \n",
    "#               fm1.xgbr.naive.pc['JRF'].mean().mean(),\n",
    "#               '------------------', i, '\\n\\n\\n\\n\\n')\n",
    "# sys.exit()\n",
    "\n",
    "#####################################################################    \n",
    "#######        FINAL BLOCK .. only use for complete results #########\n",
    "#####################################################################            \n",
    "model1 = [fm1.LM, fm1.NN, fm1.rf, fm1.xgbr]  \n",
    "model2 = [fm2.CNN, fm2.CNNLSTM, fm2.convLSTM, fm2.VRNN, fm2.LSTM, fm2.GRU]\n",
    "# fm1 = compute_stat(model1)\n",
    "# fm2 = compute_stat(model2)\n",
    "# for m in model1: #+model2\n",
    "#     print_stat_tables(m)\n",
    "# for plot_what in ['nparams', 'pc']:\n",
    "#     plot_final_results([m.exposed for m in model1+model2], 'final.exposed', plot_what)\n",
    "#     plot_final_results([m.exposed_unseen for m in model1+model2], 'final.exposed_unseen', plot_what)\n",
    "#     plot_final_results([m.naive for m in model1+model2], 'final.naive', plot_what)\n",
    "#     if plot_what in ['pc']:\n",
    "#         plot_final_results([m.naive_braced for m in model1+model2], 'final.naiveb', plot_what)\n",
    "\n",
    "#######################\n",
    "\n",
    "# fm = compute_stat([fm.NN])\n",
    "# plot_noise_results(fm)\n",
    "# print_stat_tables(fm.NN)\n",
    "\n",
    "### XGBR\n",
    "##     ##  7:0.66    ## 1:0.75\n",
    "##2:0.74     ##      ## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625d7d7-a645-488b-8025-36d1fffbd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# model1 = [fm1.LM, fm1.NN, fm1.rf, fm1.xgbr]  \n",
    "# model2 = [fm2.CNN, fm2.CNNLSTM, fm2.convLSTM, fm2.VRNN, fm2.LSTM, fm2.GRU]\n",
    "# fm1 = compute_stat(model1)\n",
    "# fm2 = compute_stat(model2)\n",
    "\n",
    "# for plot_what in ['nparams', 'pc', 'NRMSE']:\n",
    "# for plot_what in ['NRMSE','RMSE']:\n",
    "#     plot_final_results([m.exposed for m in model1+model2], 'final.exposed', plot_what)\n",
    "#     plot_final_results([m.exposed_unseen for m in model1+model2], 'final.exposed_unseen', plot_what)\n",
    "#     plot_final_results([m.naive for m in model1+model2], 'final.naive', plot_what)\n",
    "#     if plot_what in ['pc','NRMSE','RMSE']:\n",
    "#         plot_final_results([m.naive_braced for m in model1+model2], 'final.naiveb', plot_what)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a4042-9dc6-4888-b5e8-522d08a12889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model1+model2:\n",
    "    combined_plot_noise(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c3c9e-002a-4c40-a0fc-a1b9a0477a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in model1+model2:\n",
    "#     print_stat_tables(m)\n",
    "# fm1.LM = learning_curve(fm1.LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab2c1a-bac8-4655-a259-cd8cad147287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a31b7-fe8d-4946-852a-66be1d420631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fm1.NN.lc_label = 'lc'\n",
    "# learning_curve(fm1.NN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fea7a6-84f9-470f-bc8f-3442dff1a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc = learning_curve(fm1.LM)   ## done on 23 June\n",
    "# lc = learning_curve(fm1.NN)   ## done on 23 June\n",
    "# lc = learning_curve(fm1.rf)   ## done on 23 June\n",
    "# lc = learning_curve(fm2.CNN)  ## done on 23 June \n",
    "# lc = learning_curve(fm2.CNN)  ## done on 23 June \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b3123ad-cb9a-46d4-8551-8fc0c5c8cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc = learning_curve(fm2.CNNLSTM)  ## done on 9 March\n",
    "# lc = learning_curve(fm2.LSTM)  ## done on 9 March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e023193-4a35-4750-9a43-109cc52f6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_learning_curve('CNNLSTM','naive','JRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0d9fd-f761-47c8-bc96-8378c955da48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad794840-bc03-42fe-acac-bdf8f54608f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ML_analysis' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### to print the final statistics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m uuu \u001b[38;5;241m=\u001b[39m \u001b[43mfm1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m fff_exp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(uuu\u001b[38;5;241m.\u001b[39mexposed\u001b[38;5;241m.\u001b[39mpc\u001b[38;5;241m.\u001b[39mvalues(),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(fff_exp), np\u001b[38;5;241m.\u001b[39mstd(fff_exp))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ML_analysis' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "### to print the final statistics\n",
    "# uuu = fm1[0]\n",
    "# fff_exp = pd.concat(uuu.exposed.pc.values(),axis=1).values.flatten()\n",
    "# print(np.mean(fff_exp), np.std(fff_exp))\n",
    "# fff_nai = pd.concat(uuu.naive.pc.values(),axis=1).values.flatten()\n",
    "# print(np.mean(fff_nai), np.std(fff_nai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde27190-9b22-49ce-af58-95bf04c6cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a832bd8-f6c2-4ac6-8fcf-2e5861b055e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb11cf-880a-432f-b877-c6a5c7225a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_flops import flops_calculation\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define your model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_shape=(256,)),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Calculate FLOPs\n",
    "flops = flops_calculation(model, batch_size=1)\n",
    "print(f\"FLOPs: {flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1eed94-db82-464f-b1e5-d3ea48a64397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('exposed','JA','convLSTM',26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8f0cf-822f-4df7-b312-9c6c3415867a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924591e-6dd4-4ce0-94ff-1b7daf5ca04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.xgbr.feature_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f37ed-d40a-4535-aae6-d78b0a65002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa85397d-b741-43cf-b34c-fc3244d24b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
